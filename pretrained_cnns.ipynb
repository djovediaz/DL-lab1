{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying CIFAR 100 with a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the CIFAR-100 dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data(label_mode=\"coarse\")\n",
    "\n",
    "# Print the shape of the data\n",
    "print(f'Training data shape: {x_train.shape}, Training labels shape: {y_train.shape}')\n",
    "print(f'Test data shape: {x_test.shape}, Test labels shape: {y_test.shape}')\n",
    "num_classes = len(set(y_train.flatten()))\n",
    "print(f'Number of different labels: {num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_label_distribution\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Plot label distribution for training, validation, and test sets\n",
    "plot_label_distribution(y_train, 'Training Set Label Distribution')\n",
    "plot_label_distribution(y_val, 'Validation Set Label Distribution')\n",
    "plot_label_distribution(y_test, 'Test Set Label Distribution')\n",
    "#\n",
    "print(f'New training data shape: {x_train.shape}, New training labels shape: {y_train.shape}')\n",
    "print(f'Validation data shape: {x_val.shape}, Validation labels shape: {y_val.shape}')\n",
    "print(f'Test data shape: {x_val.shape}, Test labels shape: {y_val.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (x_train, y_train)\n",
    "val_dataset = (x_val, y_val)\n",
    "test_dataset = (x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try a pair of models using feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "conv_base_resnet = keras.applications.ResNet50(include_top = False,\n",
    "                                        weights = 'imagenet',\n",
    "                                        input_shape= (32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base_resnet.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base_resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")\n",
    "  \n",
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = conv_base_resnet(inputs)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(20, activation=\"softmax\")(x)\n",
    "model_resnet_fe = keras.Model(inputs, outputs)\n",
    "model_resnet_fe.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"models/resnet_fe.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\"),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=10,\n",
    "        restore_best_weights=True)\n",
    "]\n",
    "history = model_resnet_fe.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=200, \n",
    "    validation_data=(x_val, y_val), \n",
    "    callbacks=callbacks,\n",
    "    batch_size=128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot \n",
    "\n",
    "plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model_resnet_fe.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "print(f'Test accuracy: {test_accuracy * 100:.2f}%')\n",
    "print(f'Test loss: {test_loss:.4f}')\n",
    "\n",
    "# Predict the classes for the test set\n",
    "y_pred = model_resnet_fe.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "# Define the category names\n",
    "category_names = [\n",
    "    \"aquatic mammals\",\n",
    "    \"fish\",\n",
    "    \"flowers\",\n",
    "    \"food containers\",\n",
    "    \"fruit and vegetables\",\n",
    "    \"household electrical devices\",\n",
    "    \"household furniture\",\n",
    "    \"insects\",\n",
    "    \"large carnivores\",\n",
    "    \"large man-made outdoor things\",\n",
    "    \"large natural outdoor scenes\",\n",
    "    \"large omnivores and herbivores\",\n",
    "    \"medium-sized mammals\",\n",
    "    \"non-insect invertebrates\",\n",
    "    \"people\",\n",
    "    \"reptiles\",\n",
    "    \"small mammals\",\n",
    "    \"trees\",\n",
    "    \"vehicles 1\",\n",
    "    \"vehicles 2\"\n",
    "]\n",
    "\n",
    "# Plot the confusion matrix with category names\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=category_names, yticklabels=category_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base_efficient = keras.applications.EfficientNetB3(include_top = False,\n",
    "                                        weights = 'imagenet',\n",
    "                                        input_shape= (32,32,3))\n",
    "conv_base_efficient.trainable = False\n",
    "conv_base_efficient.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")\n",
    "  \n",
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = conv_base_efficient(inputs)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(20, activation=\"softmax\")(x)\n",
    "model_efficient_fe = keras.Model(inputs, outputs)\n",
    "model_efficient_fe.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"models/efficientnet_fe.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\"),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=10,\n",
    "        restore_best_weights=True)\n",
    "]\n",
    "history = model_efficient_fe.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=200, \n",
    "    validation_data=(x_val, y_val), \n",
    "    callbacks=callbacks,\n",
    "    batch_size=128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model_efficient_fe.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "print(f'Test accuracy: {test_accuracy * 100:.2f}%')\n",
    "print(f'Test loss: {test_loss:.4f}')\n",
    "\n",
    "# Predict the classes for the test set\n",
    "y_pred = model_efficient_fe.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "# Plot the confusion matrix with category names\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=category_names, yticklabels=category_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the same models but using fine tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base_resnet.trainable = True\n",
    "\n",
    "for layer in conv_base_resnet.layers[:-3]:\n",
    "    layer.trainable = False\n",
    "\n",
    "conv_base_resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")\n",
    "  \n",
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = conv_base_resnet(inputs)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(20, activation=\"softmax\")(x)\n",
    "model_resnet_ft = keras.Model(inputs, outputs)\n",
    "model_resnet_ft.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"models/resnet_ft.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\"),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=10,\n",
    "        restore_best_weights=True)\n",
    "]\n",
    "history = model_resnet_ft.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=200, \n",
    "    validation_data=(x_val, y_val), \n",
    "    callbacks=callbacks,\n",
    "    batch_size=128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model_resnet_ft.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "print(f'Test accuracy: {test_accuracy * 100:.2f}%')\n",
    "print(f'Test loss: {test_loss:.4f}')\n",
    "\n",
    "# Predict the classes for the test set\n",
    "y_pred = model_resnet_ft.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "# Plot the confusion matrix with category names\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=category_names, yticklabels=category_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base_efficient.trainable = True\n",
    "\n",
    "for layer in conv_base_efficient.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "conv_base_efficient.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")\n",
    "  \n",
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = conv_base_efficient(inputs)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(20, activation=\"softmax\")(x)\n",
    "model_efficient_ft = keras.Model(inputs, outputs)\n",
    "model_efficient_ft.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"models/efficient_ft.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\"),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=10,\n",
    "        restore_best_weights=True)\n",
    "]\n",
    "history = model_efficient_ft.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=200, \n",
    "    validation_data=(x_val, y_val), \n",
    "    callbacks=callbacks,\n",
    "    batch_size=128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model_efficient_ft.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "print(f'Test accuracy: {test_accuracy * 100:.2f}%')\n",
    "print(f'Test loss: {test_loss:.4f}')\n",
    "\n",
    "# Predict the classes for the test set\n",
    "y_pred = model_efficient_ft.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "# Plot the confusion matrix with category names\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=category_names, yticklabels=category_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
